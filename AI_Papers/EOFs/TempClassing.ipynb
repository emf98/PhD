{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fcc4b6-51d4-4276-84e7-43b9f9f46695",
   "metadata": {},
   "source": [
    "### Climatology of temperature classification. \n",
    "\n",
    "Updated April 21, 2025. (I came back to do 3 classes based on standard deviation.) \n",
    "\n",
    "And again on April 23, 2025 to add in the additional areas. \n",
    "\n",
    "This file allows you to designate your desired area from the 2-degree gridded dataset I have on hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "181fb0ec-33df-4b92-9bd9-e1efcf527bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03120d35-0d52-4b79-bff0-097d9f74a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature at 1000hPa over the full NH\n",
    "infile = open(\"FullNH_1959_temps_2deg.p\", 'rb') \n",
    "temp = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d4247d-1e62-4abf-b56f-97b4db564c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 183, 46, 180)\n"
     ]
    }
   ],
   "source": [
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26f44b8f-46cd-4b32-b70c-4acd7c5d250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove leap day\n",
    "temp = np.delete(temp,[151],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58d4cf4c-d70a-4820-ad55-5ed833a6d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "##choose desired region\n",
    "##for that europe area it is lon = (10,45 E) and lat = (60, 75 N)\n",
    "###so ... to check the indexing I am quickly going to generate some arrays to check lol\n",
    "lat = np.arange(90,-2,-2)\n",
    "lon = np.arange(0,360,2)\n",
    "\n",
    "print(len(lat))\n",
    "print(len(lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1df45-62d9-4416-a087-d3b8ce4f5f58",
   "metadata": {},
   "source": [
    "European region of interest (60-75N, 10-45W). \n",
    "\n",
    "Nova Scotia (55-70N, 70-50W/290-310) \n",
    "\n",
    "SE US (32-40N, 90-105W/255-270). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28312beb-f1c5-4f64-8bec-90811e521a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "eur_lat = lat[7:16]\n",
    "print(len(eur_lat))\n",
    "\n",
    "eur_lon = lon[5:24]\n",
    "print(len(eur_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "457f11e8-ed22-46f0-b309-6a3f07bc96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "nova_lat = lat[10:18]\n",
    "print(len(nova_lat))\n",
    "\n",
    "nova_lon = lon[145:156]\n",
    "print(len(nova_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92e3a547-ef17-4300-98f2-cdd725f0ff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "se_lat = lat[25:30]\n",
    "print(len(se_lat))\n",
    "\n",
    "se_lon = lon[127:136]\n",
    "print(len(se_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b424dc9-fd06-44d4-881e-95039257c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 182, 9, 19)\n",
      "(62, 182, 8, 11)\n",
      "(62, 182, 5, 9)\n"
     ]
    }
   ],
   "source": [
    "##designate area of northern europe\n",
    "eur_t = temp[:,:,7:16,5:24]\n",
    "print(eur_t.shape)\n",
    "\n",
    "##designate area of nova scotia\n",
    "nova_t = temp[:,:,10:18,145:156]\n",
    "print(nova_t.shape)\n",
    "\n",
    "##designate area of nova scotia\n",
    "se_t = temp[:,:,25:30,127:136]\n",
    "print(se_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40030340-51ce-4298-bebd-8d39d883b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##weighting\n",
    "##create array... \n",
    "eur_t = xr.DataArray(data= eur_t, dims = [\"year\",\"day\",\"lat\",\"lon\"],coords = dict(year = range(1959,2021,1),\n",
    "                                                                                day = range(0,182,1),\n",
    "                                                                                lat = eur_lat,\n",
    "                                                                                lon = eur_lon))\n",
    "\n",
    "nova_t = xr.DataArray(data= nova_t, dims = [\"year\",\"day\",\"lat\",\"lon\"],coords = dict(year = range(1959,2021,1),\n",
    "                                                                                day = range(0,182,1),\n",
    "                                                                                lat = nova_lat,\n",
    "                                                                                lon = nova_lon))\n",
    "\n",
    "se_t = xr.DataArray(data= se_t, dims = [\"year\",\"day\",\"lat\",\"lon\"],coords = dict(year = range(1959,2021,1),\n",
    "                                                                                day = range(0,182,1),\n",
    "                                                                                lat = se_lat,\n",
    "                                                                                lon = se_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff8565f0-152e-4e2d-a8fc-ffb51f0f0fbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##set definitions for weighting and the anomaly/median calculations...\n",
    "def weights(target):\n",
    "    weights=np.cos(np.deg2rad(target.lat))\n",
    "    weight = target.weighted(weights).mean(dim=\"lon\").mean(dim=\"lat\") #average over the full area\n",
    "    print(weight.shape)\n",
    "    return weight;\n",
    "\n",
    "def daily_anomaly(target):\n",
    "    dailymean = np.nanmean(target,axis=1)\n",
    "    anom = np.zeros_like(target)\n",
    "    for t in np.arange(target.shape[1]):\n",
    "         anom[:,t] = target[:,t] - dailymean\n",
    "    print(anom.shape)\n",
    "    return anom; \n",
    "\n",
    "def daily_median(target):\n",
    "    dailymed = np.nanmedian(target,axis=1)\n",
    "    med = np.zeros_like(target)\n",
    "    for t in np.arange(target.shape[1]):\n",
    "         med[:,t] = target[:,t] - dailymed\n",
    "    print(med.shape)\n",
    "    return med; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61c0b199-fb76-4a06-937b-df0dae3035f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 182)\n",
      "(62, 182)\n",
      "(62, 182)\n"
     ]
    }
   ],
   "source": [
    "#now calculate weights\n",
    "e_t_weight = weights(eur_t)\n",
    "n_t_weight = weights(nova_t)\n",
    "s_t_weight = weights(se_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a99b6e78-cc09-443c-a99e-f49230e56934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 182)\n",
      "(62, 182)\n",
      "(62, 182)\n",
      "(62, 182)\n",
      "(62, 182)\n",
      "(62, 182)\n"
     ]
    }
   ],
   "source": [
    "#calculate daily anomalies from area-weighted values\n",
    "anom_et = daily_anomaly(e_t_weight)\n",
    "anom_nt = daily_anomaly(n_t_weight)\n",
    "anom_st = daily_anomaly(s_t_weight)\n",
    "\n",
    "#calculate daily medians from area-weighted daily anomalies\n",
    "med_et = daily_median(anom_et)\n",
    "med_nt = daily_median(anom_nt)\n",
    "med_st = daily_median(anom_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9747b1-f29a-4649-a93e-6324a324f4c7",
   "metadata": {},
   "source": [
    "### For this next subsection, change `te1` according to whichever area you wish to process. \n",
    "\n",
    "This should be done twice ... the first time for one category and the second for the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b21425e-280b-4307-a0bd-80e209dacbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##flatten\n",
    "te1 = anom_et\n",
    "\n",
    "te1 = np.reshape(te1, (62*182))\n",
    "e_st = np.empty((62*182))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd8752ba-80af-4301-ab93-b59517e580ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for NaNs\n",
    "if np.any(np.isnan(te1)) or np.any(np.isinf(te1)):\n",
    "    print(\"NaN or Inf values found in te1!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa02055f-1c75-4384-8b53-88471ce6c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays for neg and pos classification\n",
    "pos = []\n",
    "neg = []\n",
    "neut = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb7d8d2c-691f-4579-8a1e-b61074abe083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.68869382, 7.66011027, 8.45504321, ..., 4.88880549, 3.63451554,\n",
       "       2.77087504])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "057bfa32-6068-4e14-982f-a8b817847ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.193865399538695"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(te1)\n",
    "-std/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "892656a7-387e-4695-aa11-6c822160cbcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop and classify anomalies\n",
    "for i in range(0,62*182):\n",
    "        if te1[i] > 0:\n",
    "            e_st[i] = 1\n",
    "            pos.append(1)\n",
    "            \n",
    "        elif te1[i] < 0:\n",
    "            #print(\"negative\")\n",
    "            e_st[i] = 0\n",
    "            neg.append(0)\n",
    "            \n",
    "        ##alternatine in an attempt to make arrays ... even? lol  \n",
    "        elif te1[i] == 0:\n",
    "            if len(pos) <= len(neg):\n",
    "                e_st[i] = 1\n",
    "                pos.append(1)\n",
    "            else:\n",
    "                e_st[i] = 0\n",
    "                neg.append(0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc1d828-9521-4a6b-a038-13947a178bee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#loop and classify anomalies\n",
    "for i in range(0,62*182):\n",
    "        if te1[i] > std/2:\n",
    "            e_st[i] = 1\n",
    "            pos.append(1)\n",
    "            \n",
    "        elif te1[i] < -std/2:\n",
    "            #print(\"negative\")\n",
    "            e_st[i] = 0\n",
    "            neg.append(0)\n",
    "            \n",
    "        ##alternatine in an attempt to make arrays ... even? lol  \n",
    "        elif te1[i] < std/2 and te1[i] > -std/2:\n",
    "            #print(\"neutral\")\n",
    "            e_st[i] = 2\n",
    "            neut.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "129c5562-c723-49c0-a4e6-d7b1f7218e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f07452f-b6c9-4f67-ac72-75d07fbfcf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11284\n",
      "5659\n",
      "5625\n",
      "0\n",
      "11284\n"
     ]
    }
   ],
   "source": [
    "print(len(te1))\n",
    "print(len(neg))\n",
    "print(len(pos))\n",
    "print(len(neut))\n",
    "\n",
    "print(int(len(neg))+int(len(pos))+int(len(neut)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6edbe908-023f-420b-ad49-166f7cba5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(e_st, open(\"europetemps_anom_classed.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689804f-3e08-4d4d-9e8d-768c6eaa66f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2021 Environment",
   "language": "python",
   "name": "aug21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
