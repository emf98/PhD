{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d5a97f",
   "metadata": {},
   "source": [
    "#### Sequential Feature Selection of PCs for Random Forest model using PV/GPH/EHF as input.\n",
    "\n",
    "File duplicated on April 23, 2025 and localized within the H100 cluster. \n",
    "I would like to identify the # of nodes that represent >80% of the variance for each feature. Then, I will do two models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1daedfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:39:18.606901: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-24 15:39:18.638806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-24 15:39:18.638836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-24 15:39:18.639882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-24 15:39:18.645594: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cannot import name 'float4_e2m1fn' from 'ml_dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m##import tensorflow/keras related files\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mK\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meofs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Eof\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py:54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lookup\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpsSet \u001b[38;5;66;03m# line: 169\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m toco_convert \u001b[38;5;66;03m# line: 1039\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.lite.experimental namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m authoring\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyzer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAnalyzer \u001b[38;5;28;01mas\u001b[39;00m Analyzer \u001b[38;5;66;03m# line: 35\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpResolverType \u001b[38;5;66;03m# line: 303\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.lite.experimental.authoring namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauthoring\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauthoring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatible \u001b[38;5;66;03m# line: 265\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_wrapper \u001b[38;5;28;01mas\u001b[39;00m _module_wrapper\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m], _module_wrapper\u001b[38;5;241m.\u001b[39mTFModuleWrapper):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/authoring/authoring.py:43\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converter_error_data_pb2\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstablehlo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization_options_pb2 \u001b[38;5;28;01mas\u001b[39;00m quant_opts_pb2\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite_constants\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrap_toco\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert_phase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:51\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Jax functions used by TFLite\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xla_computation \u001b[38;5;28;01mas\u001b[39;00m _xla_computation\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   _xla_computation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version_info__ \u001b[38;5;28;01mas\u001b[39;00m __version_info__\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Set Cloud TPU env vars if necessary before transitively loading C++ backend\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud_tpu_init\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cloud_tpu_init \u001b[38;5;28;01mas\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m   _cloud_tpu_init()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/cloud_tpu_init.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardware_utils\n\u001b[1;32m     23\u001b[0m running_in_cloud_tpu_vm: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/config.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Generic, NoReturn, Optional, Protocol, TypeVar, cast\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m guard_lib\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xla_client\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py:96\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pytree \u001b[38;5;28;01mas\u001b[39;00m pytree  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Device \u001b[38;5;28;01mas\u001b[39;00m Device  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla_client\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxla_client\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Jaxlib code is split between the Jax and the XLA repositories.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Only for the internal usage of the JAX developers, we expose a version\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# number that can be used to perform changes without breaking the main\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# branch on the Jax github.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m jaxlib_extension_version: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(xla_client, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_version\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/jaxlib/xla_client.py:252\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m OpMetadata(\n\u001b[1;32m    234\u001b[0m       op_type\u001b[38;5;241m=\u001b[39mop_type, op_name\u001b[38;5;241m=\u001b[39mop_name, source_file\u001b[38;5;241m=\u001b[39mfilename, source_line\u001b[38;5;241m=\u001b[39mlineno\n\u001b[1;32m    235\u001b[0m   )\n\u001b[1;32m    238\u001b[0m PrimitiveType \u001b[38;5;241m=\u001b[39m _xla\u001b[38;5;241m.\u001b[39mPrimitiveType\n\u001b[1;32m    240\u001b[0m XLA_ELEMENT_TYPE_TO_DTYPE \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    241\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mPRED: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    242\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mS4: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mint4),\n\u001b[1;32m    243\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mS8: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    244\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mS16: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    245\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mS32: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    246\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mS64: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    247\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mU4: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39muint4),\n\u001b[1;32m    248\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mU8: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    249\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mU16: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint16\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    250\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mU32: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint32\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    251\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mU64: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint64\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m--> 252\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF4E2M1FN: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[43mml_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat4_e2m1fn\u001b[49m),\n\u001b[1;32m    253\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E3M4: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e3m4),\n\u001b[1;32m    254\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E4M3: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e4m3),\n\u001b[1;32m    255\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E4M3FN: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e4m3fn),\n\u001b[1;32m    256\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E4M3B11FNUZ: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e4m3b11fnuz),\n\u001b[1;32m    257\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E4M3FNUZ: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e4m3fnuz),\n\u001b[1;32m    258\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E5M2: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e5m2),\n\u001b[1;32m    259\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E5M2FNUZ: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e5m2fnuz),\n\u001b[1;32m    260\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF8E8M0FNU: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mfloat8_e8m0fnu),\n\u001b[1;32m    261\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mBF16: np\u001b[38;5;241m.\u001b[39mdtype(ml_dtypes\u001b[38;5;241m.\u001b[39mbfloat16),\n\u001b[1;32m    262\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF16: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    263\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF32: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    264\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mF64: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    265\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mC64: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex64\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    266\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mC128: np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex128\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    267\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mTUPLE: np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mobject_),\n\u001b[1;32m    268\u001b[0m     PrimitiveType\u001b[38;5;241m.\u001b[39mTOKEN: np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mobject_),\n\u001b[1;32m    269\u001b[0m }\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Note the conversion on the key. Numpy has a known issue wherein dtype hashing\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# doesn't work as expected (https://github.com/numpy/numpy/issues/7242). Thus,\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# when keying by dtype in this dict, we use the string form of dtypes.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m DTYPE_TO_XLA_ELEMENT_TYPE \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mstr\u001b[39m(dt): et \u001b[38;5;28;01mfor\u001b[39;00m et, dt \u001b[38;5;129;01min\u001b[39;00m XLA_ELEMENT_TYPE_TO_DTYPE\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    276\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ml_dtypes/__init__.py:71\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m   warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     63\u001b[0m       (\n\u001b[1;32m     64\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_dtypes.float8_e4m3b11 is deprecated. Use\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     69\u001b[0m   )\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m float8_e4m3b11fnuz\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot import name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: cannot import name 'float4_e2m1fn' from 'ml_dtypes'"
     ]
    }
   ],
   "source": [
    "# relevant import statements\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "##just to stop the excess number of warnings\n",
    "import warnings\n",
    "from random import randint, sample, seed\n",
    "\n",
    "import cartopy.feature as cf\n",
    "import cartopy.util  # Requires separate import\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "# plotting related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # statistical data visualization\n",
    "import xarray as xr\n",
    "from cartopy import crs as ccrs  # Useful for plotting maps\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter\n",
    "from cartopy.util import add_cyclic_point\n",
    "from matplotlib import rcParams  # For changing text properties\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    brier_score_loss,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "##import tensorflow/keras related files\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from eofs.standard import Eof\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import (\n",
    "    Input,\n",
    "    Sequential,\n",
    "    constraints,\n",
    "    initializers,\n",
    "    layers,\n",
    "    optimizers,\n",
    "    regularizers,\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Activation,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    InputSpec,\n",
    "    Layer,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# tf.compat.v1.disable_v2_behavior() # <-- HERE !\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import investigate\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48eb4ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras Tuner:\u001b[39m\u001b[38;5;124m\"\u001b[39m, kt\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras Tuner:\", kt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197544a",
   "metadata": {},
   "source": [
    "The bulk of this file to start is copied from the previous EOF file/my EOF test file. \n",
    "\n",
    "##### First, I am going to pickle in the input data. I will then remove the seasonal climo from the dataset...\n",
    "\n",
    "I had to actually download the data locally and upload it here to the H100 cluster in the ./Dissertation_Coding/data folder because I could not call it from my home directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input data\n",
    "infile = open(\"../../data/extend_pv350pt.p\",\"rb\",)\n",
    "pv_input = pickle.load(infile)  ##pv on an isentropic surface, 350\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../data/1959ZMeddyheatflux.p\",\"rb\",)\n",
    "ehf_input = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()\n",
    "\n",
    "infile = open(\"../../data/1959gph.p\",\"rb\",)\n",
    "gph_input = pickle.load(infile)  ##ZMehf vertical cross section along longitudes\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_input.shape  ##63 years, october through march, 16 lats (90,60), all lons.\n",
    "#will need to remove the last year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d429c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gph_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove extra pv and gph year\n",
    "pv_input = np.delete(pv_input, [62], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c040ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehf_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be757ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_input.shape #again lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove leap day.\n",
    "pv_input = np.delete(pv_input, [151], 1)\n",
    "ehf_input = np.delete(ehf_input, [151], 1)\n",
    "gph_input = np.delete(gph_input, [151], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove seasonal climo \n",
    "def daily_anom(target):\n",
    "    dailymean = np.nanmean(target, axis=1)\n",
    "    anom = np.zeros_like(target)\n",
    "    for t in np.arange(target.shape[1]):\n",
    "        anom[:, t, :, :] = target[:, t, :, :] - dailymean\n",
    "    return anom;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7637e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##take seasonal daily average/remove seasonal climatology\n",
    "anom_pv = daily_anom(pv_input)\n",
    "print(\"ANOM PV shape: \",anom_pv.shape)\n",
    "\n",
    "anom_ehf = daily_anom(ehf_input)\n",
    "print(\"ANOM EHF shape: \",anom_ehf.shape)\n",
    "\n",
    "anom_gph = daily_anom(gph_input)\n",
    "print(\"ANOM GPH shape: \",anom_gph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check for NaNs\n",
    "if np.any(np.isnan(anom_pv)) or np.any(np.isinf(anom_pv)):\n",
    "    print(\"NaN or Inf values found in PV!\")\n",
    "\n",
    "if np.any(np.isnan(anom_ehf)) or np.any(np.isinf(anom_ehf)):\n",
    "    print(\"NaN or Inf values found in EHF!\")\n",
    "\n",
    "if np.any(np.isnan(anom_gph)) or np.any(np.isinf(anom_gph)):\n",
    "    print(\"NaN or Inf values found in GPH!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_pv[:62, 17:168, :, :].shape ##check date length\n",
    "# anom_pv[:62,31:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##flatten array to just the dates relevant to my models. \n",
    "flat_anom_pv = anom_pv[:62, 17:168, :, :].reshape((62 * 151, 24, 181))\n",
    "print(flat_anom_pv.shape)\n",
    "\n",
    "flat_EHFanom = anom_ehf[:62, 17:168, :, :].reshape((62 * 151, 37, 180))\n",
    "print(flat_EHFanom.shape)\n",
    "\n",
    "flat_GPHanom = anom_gph[:62, 17:168, :, :].reshape((62 * 151, 37, 180))\n",
    "print(flat_GPHanom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d33def",
   "metadata": {},
   "source": [
    "#### Great, so I have everything uploaded and reduced to daily anomalies with the seasonal climo removed. Fantastic, lol. \n",
    "\n",
    "Now I need to weight appropriately. lol. \n",
    "\n",
    "I do not need to do this for EHF or GPH since I already reduced them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "##I DID NOT USE THIS FOR THE EOFs, JUST TRIED TO CALCULATE HERE...\n",
    "flat_anom = xr.DataArray(\n",
    "    data=flat_anom_pv,\n",
    "    dims=[\"dates\", \"lat\", \"lon\"],\n",
    "    coords=dict(\n",
    "        dates=range(0, 9362, 1), lat=np.arange(90, 43, -2), lon=np.arange(0, 362, 2)\n",
    "    ),\n",
    ")\n",
    "wgts = np.cos(flat_anom.lat / 180 * np.pi) ** 0.5\n",
    "flat_PVanom = flat_anom * wgts\n",
    "# weights=np.cos(np.deg2rad(flat_anom.lat))\n",
    "# flat_anom = flat_anom.weighted(weights).mean(dim=\"lon\").mean(dim=\"lat\") #average over the full area\n",
    "# flat_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a633726",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_PVanom.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d705c4",
   "metadata": {},
   "source": [
    "##### Attempt at EOF analysis/PC decomp based on Zheng's example code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOF, the code above had selection of certain pressure levels and latitude bands. I do not need to do that here.\n",
    "PVsolver = Eof(flat_PVanom.values)\n",
    "EHFsolver = Eof(flat_EHFanom)\n",
    "GPHsolver = Eof(flat_GPHanom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pickle Out Solvers ...\")\n",
    "pickle.dump(PVsolver, open(\"PVsolver_14days.p\", 'wb'))\n",
    "pickle.dump(EHFsolver, open(\"EHFsolver_14days.p\", 'wb'))\n",
    "pickle.dump(GPHsolver, open(\"GPHsolver_14days.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##loop through modes to find when highest % variance is reached for each dataset. \n",
    "variance = []\n",
    "for i in range(1, 400):\n",
    "    ##select the desired number of eofs\n",
    "    nmode = i\n",
    "    # print(nmode)\n",
    "    EOF = PVsolver.eofs(neofs=nmode, eofscaling=0)\n",
    "    # print(type(EOF),np.shape(EOF))\n",
    "    ##make the EOF 2-dimensional\n",
    "    EOF2d = EOF.reshape(EOF.shape[0], EOF.shape[-2] * EOF.shape[-1])\n",
    "    # print(np.shape(EOF2d))\n",
    "    pv = np.dot(EOF2d, np.transpose(EOF2d))\n",
    "    EOF_nw2d = EOF2d\n",
    "    # print(pv.shape)\n",
    "    eigenv = PVsolver.eigenvalues(neigs=nmode)\n",
    "    VarEx = PVsolver.varianceFraction(neigs=nmode) * 100\n",
    "    variance.append(sum(VarEx))\n",
    "plt.title(\"PV PCs\")\n",
    "plt.plot(np.arange(1, 400), variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600551fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = []\n",
    "for i in range(1, 100):\n",
    "    ##select the desired number of eofs\n",
    "    nmode = i\n",
    "    # print(nmode)\n",
    "    EOF = EHFsolver.eofs(neofs=nmode, eofscaling=0)\n",
    "    # print(type(EOF),np.shape(EOF))\n",
    "    ##make the EOF 2-dimensional\n",
    "    EOF2d = EOF.reshape(EOF.shape[0], EOF.shape[-2] * EOF.shape[-1])\n",
    "    # print(np.shape(EOF2d))\n",
    "    pv = np.dot(EOF2d, np.transpose(EOF2d))\n",
    "    EOF_nw2d = EOF2d\n",
    "    # print(pv.shape)\n",
    "    eigenv = EHFsolver.eigenvalues(neigs=nmode)\n",
    "    VarEx = EHFsolver.varianceFraction(neigs=nmode) * 100\n",
    "    variance.append(sum(VarEx))\n",
    "plt.title(\"EHF PCs\")\n",
    "plt.plot(np.arange(1, 100), variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f646fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = []\n",
    "for i in range(1, 50):\n",
    "    ##select the desired number of eofs\n",
    "    nmode = i\n",
    "    # print(nmode)\n",
    "    EOF = GPHsolver.eofs(neofs=nmode, eofscaling=0)\n",
    "    # print(type(EOF),np.shape(EOF))\n",
    "    ##make the EOF 2-dimensional\n",
    "    EOF2d = EOF.reshape(EOF.shape[0], EOF.shape[-2] * EOF.shape[-1])\n",
    "    # print(np.shape(EOF2d))\n",
    "    pv = np.dot(EOF2d, np.transpose(EOF2d))\n",
    "    EOF_nw2d = EOF2d\n",
    "    # print(pv.shape)\n",
    "    eigenv = GPHsolver.eigenvalues(neigs=nmode)\n",
    "    VarEx = GPHsolver.varianceFraction(neigs=nmode) * 100\n",
    "    variance.append(sum(VarEx))\n",
    "plt.title(\"GPH PCs\")\n",
    "plt.plot(np.arange(1, 50), variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74748ee8",
   "metadata": {},
   "source": [
    "#### PV = 175 PCs. \n",
    "#### EHF = 45 PCs. \n",
    "#### GPH = 12 PCs. \n",
    "\n",
    "Now run EOF analysis with the \"correct\" inital number of modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74670e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
