When I pushed this most recently, this was the case. I am waiting for ITs to fix the container again. hahaah

If you look at one of my EOF Solver Python notebooks, you can see the massive error from tensorflow. 

THERE IS NO DATA IN THIS FOLDER BECAUSE WE ARE ON GITHUB.

#################################################
Job Created 4/24/2025 (I BROKE THE CONTAINER)
OKAY SO... In the same vein as the previous file I had to restart here but specifically within the graphcast container because... well.. the tensorflow container keeps dying. No idea why.

This is a COPY of the other file. I just want to see if the container makes a difference in the environment not killing itself every 30 minutes when my computer is open and connected to the internet. (SPOILER ALERT: It does but I broke the container) 

This file is going to get its own special file for temperature data files reflecting the three regions I pulled from the Butler et al 2017 paper. 

#################################################
Eurasia -> (60-75N, 10-45W)
Nova Scotia -> (55-70N, 70-50W/290-310)
SE United States -> (32-40N, 90-105W/255-270)

I am also introducing a slightly modified PV file. This one extends down into the midlatitudes and contains some extrapolation to cover missing data from 358-360 longitude. (extend_pv350.p)

I am going to create a few separate folders here to designate coding tasks:
    - `EOF_Analysis` at 10 and 14 days, create the SOLVERS for each of my input features. 
       THE SOLVERS WILL BE LOCATED IN THIS FILE.
       -> EOF_def.py (definition statement)
       -> 10Day_EOFSolvers.ipynb and 14Day_EOFSolvers.ipynb
       
    - `SFS_Model` at 10 and 14 days ... this is where it will get messy because there will be 12 separate python files to
       conduct sequential feature selection for each region. 
       I want to do one for each time step (8 features only) at each region BUT I want to see if there are differences 
       between the two different classed datasets ...
       
       I PLAN TO START WITH JUST EUROPE AND MOVE ON TO THE SECOND AREAS AFTER I HAVE A WORK FLOW SOLIDIFIED. 
       
    - `ModelTraining` the EOF model testing and training folder ... this may also be designated by region. 

#########
I do not have to redo the EOF analysis because nothing data-wise has changed. The only thing that has changed is the environment. 
I have to wonder if my running 12 python scripts is what is killing it ... maybe. TBD. Don't know if you don't try.

For 14-days I have the respective number of PCs:
#### PV = 175 PCs. 
#### EHF = 45 PCs. 
#### GPH = 12 PCs. 

For 10-days I have the respective number of PCs:
#### PV = 200 PCs. 
#### EHF = 55 PCs. 
#### GPH = 12 PCs. 

I got all four python files for conducting SFS set up for Europe. (6:50 PM 4/23) ... (4/24, I will be playing with these again.)
/mnt/ef935217/Dissertation_Coding/Jo/SFS_Model/Europe/ (FILE LOCATION)
########################################################################################
nohup python -u Europe10Day_EOF.py >& E10_2output.txt & disown
nohup python -u Europe_three_10Day_EOF.py >& E10_3output.txt & disown
nohup python -u Europe14Day_EOF.py >& E14_2output.txt & disown
nohup python -u Europe_three_14Day_EOF.py >& E14_3output.txt & disown


ps -wx (check if job is running)

I am also moving over/duplicating the files for NS and SEUS
########################################################################################
nohup python -u NS10Day_EOF.py >& N10_2output.txt & disown
nohup python -u NS_three_10Day_EOF.py >& N10_3output.txt & disown
nohup python -u NS14Day_EOF.py >& N14_2output.txt & disown
nohup python -u NS_three_14Day_EOF.py >& N14_3output.txt & disown
########################################################################################
nohup python -u SEUS10Day_EOF.py >& S10_2output.txt & disown
nohup python -u SEUS_three_10Day_EOF.py >& S10_3output.txt & disown
nohup python -u SEUS14Day_EOF.py >& S14_2output.txt & disown
nohup python -u SEUS_three_14Day_EOF.py >& S14_3output.txt & disown
########################################################################################
Update on 4/25:
We were able to get the container working. 
I am waiting for the cross-validation/SFS to finish and then I can start to work on plotting the PCs and running the model tuner. :)
One of the current jobs is in the old Graphcast container and the other in the new one ...

I also started moving tuning files around. I am going to need to take all of that process VERY SLOWLY AND ONE REGION AT A TIME TO MINIMIZE CONFUSION BECAUSE THERE VERY WELL MAY BE 6 SEPARATE MODELS. 
My goal here is really to train one model for each time step and see if that translates to the different regions. 
The purpose of doing 2 and 3 classes was purely to see if different features were selected.... so far it looks like no. But I will not be able to tell definitively until I have it all set up and finished.  

THERE ARE NO MODEL ARCHITECTURES OR TUNING FILES IN THE SUB-FOLDERS OF ModelTraining YET. 

########################################################################################

Update on 4/28:

So,
The SFS is still not done. I initiated it around, like, 8 PM on Thursday?
It is now 4 PM on Monday. Almost four days later!

I will spin up the next go SFS after this one finishes. 

My plan, at least to start, is to tune a model for one timestep/one set of classes for Europe and see if that same architecture works for the other regions/time steps/etc. 
For example, I would take three classes in Europe for 14 days. Tune a model. See if it works for the other scenarios. 

I would also like to add the attention layer + get SHAP working in some way for the LSTM model architecture before doing all of the regions. 

########################################################################################
Update on 4/29:

SFS finished last night around midnight. (Ran for four days.)
I plan to start the remaining SFS today.

On initial look, it seems like the time steps and number of classes didn't matter within Europe for choosing the same features ... 
########################################################################################
Update on 4/30:

On analyzing some of the PCs, I found that I was using too high an isentropic level for PV, and now I have to start over with the EOFs and SFS.
350K was capturing the midlatitude jet behavior rather than the polar jet, which would have been ideal. 
It's fine. Everything is fine. 

For 14-days I have the respective number of PCs:
#### PV = 100 PCs. 
#### EHF = 40 PCs. 
#### GPH = 10 PCs. 

For 10-days I have the respective number of PCs:
#### PV = 100 PCs. 
#### EHF = 40 PCs. 
#### GPH = 10 PCs.

########################################################################################
Update on 5/1:
We love a non-linear research process! 
I am backtracking even further to changing my temperature data classifications. 

The question will now be whether I can predict the likelihood of a cold anomaly with these features? Does this change based on region? Do the regions identify different features from these cross sections? 

My target output now has classes of 1 for cold anomaly (<-0.5 standard deviation) and 0 for everything else.

I would hypothesize that this varies based on the region of interest. 
I think for Eurasia, I may have more success predicting the likelihood based on downward propagating features from the stratosphere, but maybe less so for Nova Scotia. Perhaps NS is affected more by a strong and relatively stable stratosphere. 

I am going to fix the temperature data files, these will be two classes ONLY per region and lead time. (So only 6 python SFS files instead of 12). 