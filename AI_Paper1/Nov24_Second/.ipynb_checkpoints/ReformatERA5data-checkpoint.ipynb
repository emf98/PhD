{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41f4984-2b54-4886-a5a2-ee7805df467d",
   "metadata": {},
   "source": [
    "#### Code to download and separate geopotential height data.\n",
    "\n",
    "Updated: November 6, 2024\n",
    "\n",
    "I moved files around for the purpose of making things more organized for this project. This is an old coding file that goes through and saves ERA5 data in a more manageable xarray format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d2e30d-e0e9-4474-9392-a58069d8437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/knight/anaconda_jan21/envs/aug21/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#import statements... I think these are all of the relevant ones to what I am doing here. \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "import netCDF4\n",
    "import os\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2493bdd-1e53-44be-b6ed-b967f6d3bcd6",
   "metadata": {},
   "source": [
    "I'm going to loop through gph and temp dates to create arrays of values for the levels and whatnot that I am looking for. \n",
    "\n",
    "I had to separate these into two files due to their size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f606856c-37d8-4dfd-8a85-44fc23be59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year = [i for i in range(1991,2022)] #indicate years for data, needed for opening files\n",
    "year = [i for i in range(1959,1991)] \n",
    "#index = [i for i in range(1,43)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc47aa7e-9541-4321-acfe-58ce19ee9224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1d414e-18cb-455d-9c2d-f56680609322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays for the years of data\n",
    "gph = np.empty((len(year),152,361,1440))\n",
    "gph[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1077b699-6eeb-44a0-8bc0-ecfcd4a9af02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/knight/anaconda_jan21/envs/aug21/lib/python3.8/site-packages/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'rasterio' loading failed:\n",
      "(numpy 1.24.3 (/nfs/home11/grad/2020/ef935217/.local/lib/python3.8/site-packages), Requirement.parse('numpy<1.23.0,>=1.16.5'), {'scipy'})\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n"
     ]
    }
   ],
   "source": [
    "#this is my attempt at looping through gph and combining the files lol\n",
    "for i in range(len(year)):\n",
    "    print(year[i])\n",
    "    #start by designating leap years because those arrays will be of a different size\n",
    "    ##1959\n",
    "    #if year[i] == 1991 or year[i] == 1995 or year[i] == 1999 or year[i] == 2003 or year[i] == 2007 or year[i] == 2011 or year[i] == 2015 or year[i] == 2019:\n",
    "    if year[i] == 1959 or year[i] == 1963 or year[i] == 1967 or year[i] == 1971 or year[i] == 1975 or year[i] == 1979 or year[i] == 1983 or year[i] == 1987:\n",
    "        \n",
    "        gfile1 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i])+\".nc\")\n",
    "        g_files1 = gfile1[\"z\"] \n",
    "        g_data1 = g_files1.loc[dict(level=500)]\n",
    "        time_coord1 = g_data1.time.values\n",
    "        values1 =  g_data1.values\n",
    "        \n",
    "        #file 2 for end\n",
    "        gfile2 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i]+1)+\".nc\")\n",
    "        g_files2 = gfile2[\"z\"] #next line will reduce this to the mean \n",
    "        g_data2 = g_files2.loc[dict(level=500)]\n",
    "        time_coord2 = g_data2.time.values\n",
    "        values2 =  g_data2.values\n",
    "\n",
    "        #combine into np array\n",
    "        gph[i,:61,:,:] = values1[90:,:,:]\n",
    "        gph[i,61:,:,:] = values2[:91,:,:] \n",
    "        continue\n",
    "        \n",
    "    #this loop is because of the weird indexing in years of leap years\n",
    "    ###1959\n",
    "    #if year[i] == 1992 or year[i] == 1996 or year[i] == 2000 or year[i] == 2004 or year[i] == 2008 or year[i] == 2012 or year[i] == 2016 or year[i] == 2020:\n",
    "    if  year[i] == 1960 or  year[i] == 1964 or  year[i] == 1968 or  year[i] == 1972 or  year[i] == 1976 or year[i] == 1980 or year[i] == 1984 or year[i] == 1988:\n",
    "        gfile1 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i])+\".nc\")\n",
    "        g_files1 = gfile1[\"z\"] #next line will reduce this to the mean \n",
    "        g_data1 = g_files1.loc[dict(level=500)]\n",
    "        values1 =  g_data1.values\n",
    "        \n",
    "        #file 2 for end\n",
    "        gfile2 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i]+1)+\".nc\")\n",
    "        g_files2 = gfile2[\"z\"] #next line will reduce this to the mean\n",
    "        g_data2 = g_files2.loc[dict(level=500)]\n",
    "        values2 =  g_data2.values\n",
    "\n",
    "        #combine into np array\n",
    "        gph[i,:61,:,:] = values1[91:,:,:]\n",
    "        gph[i,61:120,:,:] = values2[:59,:,:]\n",
    "        gph[i,121:,:,:] = values2[60:91,:,:]\n",
    "        continue\n",
    "    #everything else and repeat \n",
    "    else:\n",
    "        gfile1 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i])+\".nc\")\n",
    "        g_files1 = gfile1[\"z\"] #next line will reduce this to the mean over th\n",
    "        g_data1 = g_files1.loc[dict(level=500)]\n",
    "        values1 =  g_data1.values\n",
    "\n",
    "        gfile2 = xr.open_dataset(\"../../../era5/gph/era5_gph_\"+str(year[i]+1)+\".nc\")\n",
    "        g_files2 = gfile2[\"z\"] #next line will reduce this to the mean \n",
    "        g_data2 = g_files2.loc[dict(level=500)]\n",
    "        values2 =  g_data2.values\n",
    "        \n",
    "        gph[i,:61,:,:] = values1[90:,:,:]\n",
    "        gph[i,61:120,:,:] = values2[:59,:,:]\n",
    "        gph[i,121:,:,:] = values2[60:91,:,:]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53c08ba-a2de-40ba-9742-14ca42c2bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 152, 361, 1440)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4062df68-7e24-4fbb-a3ba-86d1229df813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gph, open(\"FullNH_500_temp_1959_PT1.p\", 'wb')) #download was changed because temperature\n",
    "#i also did NOT divide by 10 here to conserve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3817b-351f-4fb8-8c49-d84a4e240591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2021 Environment",
   "language": "python",
   "name": "aug21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
